{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f5e28ef",
   "metadata": {},
   "source": [
    "### EXPLORACIÓN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ca9ab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: (4950, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_agresividad = pd.read_csv('../datasets/train_agresividad.tsv', sep='\\t')\n",
    "print(f\"Dataset cargado: {df_agresividad.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6db33dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRIMERAS FILAS:\n",
      "      id                                               text  HS  TR  AG\n",
      "0  20001  Easyjet quiere duplicar el número de mujeres p...   1   0   0\n",
      "1  20002  El gobierno debe crear un control estricto de ...   1   0   0\n",
      "2  20003  Yo veo a mujeres destruidas por acoso laboral ...   0   0   0\n",
      "3  20004  — Yo soy respetuoso con los demás, sólamente l...   0   0   0\n",
      "4  20007  Antonio Caballero y como ser de mal gusto e ig...   0   0   0\n",
      "\n",
      "INFORMACIÓN DE COLUMNAS:\n",
      "['id', 'text', 'HS', 'TR', 'AG']\n",
      "\n",
      "VALORES ÚNICOS POR COLUMNA:\n",
      "id: 4950 valores únicos\n",
      "text: 4950 valores únicos\n",
      "HS: 2 valores únicos\n",
      "TR: 2 valores únicos\n",
      "AG: 2 valores únicos\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPRIMERAS FILAS:\")\n",
    "print(df_agresividad.head())\n",
    "\n",
    "print(\"\\nINFORMACIÓN DE COLUMNAS:\")\n",
    "print(df_agresividad.columns.tolist())\n",
    "\n",
    "print(\"\\nVALORES ÚNICOS POR COLUMNA:\")\n",
    "for col in df_agresividad.columns:\n",
    "    unicos = df_agresividad[col].nunique()\n",
    "    print(f\"{col}: {unicos} valores únicos\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2906a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NULOS por columna:\n",
      " id      0\n",
      "text    0\n",
      "HS      0\n",
      "TR      0\n",
      "AG      0\n",
      "dtype: int64\n",
      "\n",
      "DUPLICADOS en 'text': 0\n",
      "\n",
      "Distribución AG (agresividad):\n",
      "AG\n",
      "0    3294\n",
      "1    1656\n",
      "Name: count, dtype: int64 \n",
      "Porcentaje:\n",
      "AG\n",
      "0    66.55\n",
      "1    33.45\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNULOS por columna:\\n\", df_agresividad.isnull().sum())\n",
    "print(\"\\nDUPLICADOS en 'text':\", df_agresividad.duplicated('text').sum())\n",
    "\n",
    "print(\"\\nDistribución AG (agresividad):\")\n",
    "print(df_agresividad['AG'].value_counts(), \"\\nPorcentaje:\")\n",
    "print((df_agresividad['AG'].value_counts(normalize=True) * 100).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb208b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución HS (hate speech):\n",
      "HS\n",
      "0    2895\n",
      "1    2055\n",
      "Name: count, dtype: int64 \n",
      "Porcentaje:\n",
      "HS\n",
      "0    58.48\n",
      "1    41.52\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDistribución HS (hate speech):\")\n",
    "print(df_agresividad['HS'].value_counts(), \"\\nPorcentaje:\")\n",
    "print((df_agresividad['HS'].value_counts(normalize=True) * 100).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb5c0f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CROSS TAB AG vs HS:\n",
      "AG     0     1\n",
      "HS            \n",
      "0   2895     0\n",
      "1    399  1656\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nCROSS TAB AG vs HS:\")\n",
    "print(pd.crosstab(df_agresividad['HS'], df_agresividad['AG']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfeb9051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas de longitud (chars):\n",
      "count    4950.000000\n",
      "mean      129.783838\n",
      "std       111.071848\n",
      "min         6.000000\n",
      "25%        74.000000\n",
      "50%       114.000000\n",
      "75%       169.000000\n",
      "max      5996.000000\n",
      "\n",
      "Estadísticas de palabra (word_count):\n",
      "count    4950.000000\n",
      "mean       21.376566\n",
      "std        19.270690\n",
      "min         1.000000\n",
      "25%        12.000000\n",
      "50%        19.000000\n",
      "75%        28.000000\n",
      "max      1057.000000\n"
     ]
    }
   ],
   "source": [
    "df_agresividad['char_len'] = df_agresividad['text'].astype(str).map(len)\n",
    "df_agresividad['word_count'] = df_agresividad['text'].astype(str).map(lambda s: len(str(s).split()))\n",
    "print(\"\\nEstadísticas de longitud (chars):\")\n",
    "print(df_agresividad['char_len'].describe().to_string())\n",
    "\n",
    "print(\"\\nEstadísticas de palabra (word_count):\")\n",
    "print(df_agresividad['word_count'].describe().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44935da6",
   "metadata": {},
   "source": [
    "### CARGAR STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f551823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords cargadas: 647 palabras\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open('../datasets/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords_crudas = f.read().splitlines()\n",
    "\n",
    "stopwords = []\n",
    "for word in stopwords_crudas:\n",
    "    try:\n",
    "        cleaned = word.encode('latin-1').decode('utf-8', errors='ignore')\n",
    "        cleaned = cleaned.strip().lower()\n",
    "        if cleaned:\n",
    "            stopwords.append(cleaned)\n",
    "    except:\n",
    "        cleaned = word.strip().lower()\n",
    "        if cleaned:\n",
    "            stopwords.append(cleaned)\n",
    "\n",
    "stopwords_extra = ['http', 'https', 'www', 'com', 'twitter', 'tweet', 'rt', 'user']\n",
    "stopwords.extend(stopwords_extra)\n",
    "\n",
    "stopwords = list(set(stopwords))\n",
    "print(f\"Stopwords cargadas: {len(stopwords)} palabras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd1fd631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_texto(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        return \n",
    "    \n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'@\\w+', '', texto)\n",
    "    texto = re.sub(r'#\\w+', '', texto)\n",
    "    texto = re.sub(r'http\\S+|www\\S+|https\\S+', '', texto)\n",
    "    texto = re.sub(r'[^\\w\\sáéíóúñ]', ' ', texto)\n",
    "    texto = re.sub(r'\\b\\d+\\b', ' ', texto)\n",
    "    palabras = texto.split()\n",
    "    palabras_filtradas = [p for p in palabras if p not in stopwords]\n",
    "    texto_limpio = ' '.join(palabras_filtradas)\n",
    "    texto_limpio = re.sub(r'\\s+', ' ', texto_limpio).strip()\n",
    "    \n",
    "    return texto_limpio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ebce5b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARACIÓN\n",
      "  Original (108 chars): Easyjet quiere duplicar el número de mujeres piloto' Verás t...\n",
      "  Limpio (61 chars): easyjet duplicar número mujeres piloto verás tú aparcar avió...\n",
      "ESTADÍSTICAS DE LIMPIEZA:\n",
      "  Longitud promedio original: 130 chars\n",
      "  Longitud promedio limpia: 68 chars\n",
      "  Reducción promedio: 62 chars\n"
     ]
    }
   ],
   "source": [
    "df_agresividad['text_limpio'] = df_agresividad['text'].apply(preprocesar_texto)\n",
    "\n",
    "print(\"COMPARACIÓN\")\n",
    "for i in range(1):\n",
    "    original = df_agresividad.iloc[i]['text']\n",
    "    limpio = df_agresividad.iloc[i]['text_limpio']\n",
    "    print(f\"  Original ({len(original)} chars): {original[:60]}...\")\n",
    "    print(f\"  Limpio ({len(limpio)} chars): {limpio[:60]}...\")\n",
    "\n",
    "print(f\"ESTADÍSTICAS DE LIMPIEZA:\")\n",
    "df_agresividad['longitud_limpia'] = df_agresividad['text_limpio'].apply(len)\n",
    "print(f\"  Longitud promedio original: {df_agresividad['char_len'].mean():.0f} chars\")\n",
    "print(f\"  Longitud promedio limpia: {df_agresividad['longitud_limpia'].mean():.0f} chars\")\n",
    "print(f\"  Reducción promedio: {(df_agresividad['char_len'].mean() - df_agresividad['longitud_limpia'].mean()):.0f} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "374929fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (textos limpios): (4950,)\n",
      "y (etiquetas AG): (4950,)\n",
      "Distribución de AG: {0: 3294, 1: 1656}\n",
      "  No agresivo (0): 3294 (66.5%)\n",
      "  Agresivo (1): 1656 (33.5%)\n",
      "DIVISIÓN COMPLETADA\n",
      "  Train: (3960,) (80.0%)\n",
      "  Test: (990,) (20.0%)\n",
      "  Train No agresivo: 2635 (66.5%)\n",
      "  Train Agresivo: 1325 (33.5%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_agresividad['text_limpio']  \n",
    "y = df_agresividad['AG']           \n",
    "\n",
    "print(f\"X (textos limpios): {X.shape}\")\n",
    "print(f\"y (etiquetas AG): {y.shape}\")\n",
    "print(f\"Distribución de AG: {y.value_counts().to_dict()}\")\n",
    "print(f\"  No agresivo (0): {y.value_counts()[0]} ({y.value_counts(normalize=True)[0]*100:.1f}%)\")\n",
    "print(f\"  Agresivo (1): {y.value_counts()[1]} ({y.value_counts(normalize=True)[1]*100:.1f}%)\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  \n",
    ")\n",
    "\n",
    "print(f\"DIVISIÓN COMPLETADA\")\n",
    "print(f\"  Train: {X_train.shape} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test: {X_test.shape} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Train No agresivo: {(y_train == 0).sum()} ({(y_train == 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Train Agresivo: {(y_train == 1).sum()} ({(y_train == 1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97dc3ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorización completada\n",
      "Train TF-IDF: (3960, 2754)\n",
      "Test TF-IDF: (990, 2754)\n",
      "Vocabulario: 2754 palabras\n",
      "\n",
      "MUESTRA\n",
      "Primeras 20 palabras: ['abajo', 'abierta', 'abogada', 'aborto', 'abran', 'abrazo', 'abre', 'abrir', 'abuela', 'abuelo', 'abuso', 'abuso violación', 'aca', 'acaba', 'acaban', 'acabar', 'acabará', 'acabo', 'acaso', 'aceptar']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=3000,      \n",
    "    min_df=3,               \n",
    "    max_df=0.85,            \n",
    "    stop_words=stopwords,   \n",
    "    ngram_range=(1, 2),     \n",
    "    analyzer='word'\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Vectorización completada\")\n",
    "print(f\"Train TF-IDF: {X_train_tfidf.shape}\")\n",
    "print(f\"Test TF-IDF: {X_test_tfidf.shape}\")\n",
    "print(f\"Vocabulario: {len(vectorizer.get_feature_names_out())} palabras\")\n",
    "\n",
    "print(f\"\\nMUESTRA\")\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(f\"Primeras 20 palabras: {vocab[:20].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d4890d",
   "metadata": {},
   "source": [
    "###  RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9f0e3479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.7758\n",
      " F1-Score: 0.6616\n",
      "\n",
      "REPORTE DE CLASIFICACIÓN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Agresivo       0.83      0.84      0.83       659\n",
      "    Agresivo       0.67      0.66      0.66       331\n",
      "\n",
      "    accuracy                           0.78       990\n",
      "   macro avg       0.75      0.75      0.75       990\n",
      "weighted avg       0.77      0.78      0.78       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',  \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "print(f\" Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\" F1-Score: {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "\n",
    "print(\"\\nREPORTE DE CLASIFICACIÓN:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['No Agresivo', 'Agresivo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6051097c",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d94b225c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.7838\n",
      "  F1-Score: 0.6825\n",
      "REPORTE DE CLASIFICACIÓN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Agresivo       0.84      0.83      0.84       659\n",
      "    Agresivo       0.67      0.69      0.68       331\n",
      "\n",
      "    accuracy                           0.78       990\n",
      "   macro avg       0.76      0.76      0.76       990\n",
      "weighted avg       0.79      0.78      0.78       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    C=1.0,\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "print(\"REPORTE DE CLASIFICACIÓN:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['No Agresivo', 'Agresivo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d71864df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado: ../models/modelo_agresividad_v1_20251210_0123.pkl\n",
      "Vectorizador guardado: ../models/vectorizer_agresividad_v1_20251210_0123.pkl\n",
      "Stopwords guardadas: ../models/stopwords_agresividad_v1_20251210_0123.json\n",
      "Metadata guardada: ../models/metadata_agresividad_v1_20251210_0123.json\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "if not os.path.exists('../models'):\n",
    "    os.makedirs('../models')\n",
    "    print(\"✓ Carpeta 'models' creada\")\n",
    "\n",
    "modelo_path = f'../models/modelo_agresividad_v1_{timestamp}.pkl'\n",
    "joblib.dump(lr_model, modelo_path)\n",
    "\n",
    "vectorizer_path = f'../models/vectorizer_agresividad_v1_{timestamp}.pkl'\n",
    "joblib.dump(vectorizer, vectorizer_path)\n",
    "\n",
    "stopwords_path = f'../models/stopwords_agresividad_v1_{timestamp}.json'\n",
    "with open(stopwords_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(stopwords, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "metadata = {\n",
    "    'nombre_modelo': 'Logistic Regression',\n",
    "    'accuracy': 0.7838,\n",
    "    'f1_score': 0.6825,\n",
    "    'precision_agresivo': 0.67,\n",
    "    'recall_agresivo': 0.69,\n",
    "    'dataset_size': 4950,\n",
    "    'train_size': 3960,\n",
    "    'test_size': 990,\n",
    "    'distribucion': {'No agresivo': 3294, 'Agresivo': 1656},\n",
    "    'vocabulario_size': 2754,\n",
    "    'stopwords_size': 647,\n",
    "    'fecha_entrenamiento': timestamp,\n",
    "    'hiperparametros': lr_model.get_params(),\n",
    "    'limitaciones_conocidas': [\n",
    "        'Falsos negativos en lenguaje sutilmente agresivo',\n",
    "        'Precisión clase agresivo: 67%',\n",
    "        'Recall clase agresivo: 69%'\n",
    "    ],\n",
    "    'recomendaciones_mejora': [\n",
    "        'Incorporar análisis léxico específico de odio',\n",
    "        'Añadir características estilísticas (longitud, puntuación)',\n",
    "        'Usar dataset_sentimiento.txt para análisis de negatividad'\n",
    "    ]\n",
    "}\n",
    "\n",
    "metadata_path = f'../models/metadata_agresividad_v1_{timestamp}.json'\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "joblib.dump(lr_model, '../models/modelo_agresividad.pkl')\n",
    "joblib.dump(vectorizer, '../models/vectorizer_agresividad.pkl')\n",
    "\n",
    "print(f\"Modelo guardado: {modelo_path}\")\n",
    "print(f\"Vectorizador guardado: {vectorizer_path}\")\n",
    "print(f\"Stopwords guardadas: {stopwords_path}\")\n",
    "print(f\"Metadata guardada: {metadata_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "707b2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_agresividad(texto, modelo=lr_model, vectorizador=vectorizer, umbral_confianza=0.65):\n",
    "    try:\n",
    "        texto_limpio = preprocesar_texto(texto)\n",
    "        texto_vectorizado = vectorizador.transform([texto_limpio])\n",
    "        \n",
    "        prediccion = modelo.predict(texto_vectorizado)[0]\n",
    "        probabilidad = modelo.predict_proba(texto_vectorizado)[0]\n",
    "        confianza = probabilidad[1] if prediccion == 1 else probabilidad[0]\n",
    "        \n",
    "        resultado = {\n",
    "            'texto_original': texto,\n",
    "            'texto_preprocesado': texto_limpio,\n",
    "            'prediccion': 'Agresivo' if prediccion == 1 else 'No agresivo',\n",
    "            'prediccion_num': int(prediccion),\n",
    "            'confianza': float(confianza),\n",
    "            'probabilidades': {\n",
    "                'No agresivo': float(probabilidad[0]),\n",
    "                'Agresivo': float(probabilidad[1])\n",
    "            },\n",
    "            'decisivo': confianza >= umbral_confianza,\n",
    "            'explicacion': []\n",
    "        }\n",
    "        \n",
    "        if prediccion == 1 and probabilidad[1] > 0.6:\n",
    "            resultado['explicacion'].append(f\"Alta probabilidad de agresividad ({probabilidad[1]:.1%})\")\n",
    "        elif prediccion == 0 and probabilidad[0] > 0.6:\n",
    "            resultado['explicacion'].append(f\"Alta probabilidad de no ser agresivo ({probabilidad[0]:.1%})\")\n",
    "        \n",
    "        if not resultado['decisivo']:\n",
    "            resultado['mensaje'] = f'Confianza insuficiente ({confianza:.1%} < {umbral_confianza:.0%}) - Revisión manual recomendada'\n",
    "        \n",
    "        return resultado\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'prediccion': 'Error en procesamiento',\n",
    "            'confianza': 0.0,\n",
    "            'decisivo': False\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "040c11f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo 1:\n",
      "'Odio a todos los inmigrantes, deberían regresar a sus países de mierda'\n",
      "Predicción: Agresivo (59.8% confianza)\n",
      "Probabilidades: No agresivo 40.2% | Agresivo 59.8%\n",
      "Decisivo: False\n",
      "Ejemplo 2:\n",
      "'Hoy hace buen clima, me gusta pasear por el parque con mis amigos'\n",
      "Predicción: No agresivo (80.8% confianza)\n",
      "Probabilidades: No agresivo 80.8% | Agresivo 19.2%\n",
      "Decisivo: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ejemplos_prueba = [\n",
    "    \"Odio a todos los inmigrantes, deberían regresar a sus países de mierda\",\n",
    "    \"Hoy hace buen clima, me gusta pasear por el parque con mis amigos\",\n",
    "]\n",
    "\n",
    "for i, ejemplo in enumerate(ejemplos_prueba, 1):\n",
    "    resultado = predecir_agresividad(ejemplo)\n",
    "    \n",
    "    print(f\"Ejemplo {i}:\")\n",
    "    print(f\"'{ejemplo}'\")\n",
    "    print(f\"Predicción: {resultado['prediccion']} ({resultado['confianza']:.1%} confianza)\")\n",
    "    print(f\"Probabilidades: No agresivo {resultado['probabilidades']['No agresivo']:.1%} | Agresivo {resultado['probabilidades']['Agresivo']:.1%}\")\n",
    "    print(f\"Decisivo: {resultado['decisivo']}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
